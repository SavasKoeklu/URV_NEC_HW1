{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import MyNeuralNetwork_New\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch network class for comparison with our network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "# pyTorch neural network class\n",
    "\n",
    "class myPytorchNetwork(nn.Module):\n",
    "    def __init__(self, layers, activation):\n",
    "        super(myPytorchNetwork, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # TODO: I'm using relus everywhere for now, we need to change it to be adjustable\n",
    "        for layer in self.fc_layers[:-1]:\n",
    "            if self.activation == 'linear':\n",
    "                x = layer(x)\n",
    "            elif self.activation == 'relu':\n",
    "                x = F.relu(layer(x))\n",
    "            elif self.activation == 'sigmoid':\n",
    "                x = torch.sigmoid(layer(x))\n",
    "            elif self.activation == 'tanh':\n",
    "                x = torch.tanh(layer(x))\n",
    "            else:\n",
    "                raise ValueError(f\"Activation funtion {self.activation} is invalid\")\n",
    "\n",
    "\n",
    "        # No need for activation in the last layer\n",
    "        return self.fc_layers[-1](x)\n",
    "\n",
    "\n",
    "def train_torch_network(network: myPytorchNetwork, dataset, max_epochs, batch_size, train_ratio=0.7,\n",
    "                        learning_rate=0.001, momentum=0.9, silent=False):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # TODO: think of making the learning rate adaptive here, e.g. by using pytorch LR scheduler\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    split_index = int(dataset.shape[0] * train_ratio)\n",
    "    train, validation = dataset[:split_index, :], torch.from_numpy(dataset[split_index:, :])\n",
    "\n",
    "    best_validation_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        np.random.shuffle(train)\n",
    "        torch_train = torch.from_numpy(train)\n",
    "        batch_start_idx = 0\n",
    "\n",
    "        batches_loss = []\n",
    "        # This way we skip last samples if there are less than batch_size of them\n",
    "        while batch_start_idx + batch_size <= torch_train.shape[0]:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(torch_train[batch_start_idx:batch_start_idx + batch_size, :-1])\n",
    "            loss = loss_fn(torch.flatten(outputs), torch_train[batch_start_idx:batch_start_idx + batch_size, -1])\n",
    "            batches_loss.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            batch_start_idx += batch_size\n",
    "\n",
    "        # Now, check the loss on validation dataset\n",
    "        validation_output = torch.flatten(network(validation[:, :-1]))\n",
    "        validation_loss = loss_fn(validation_output, validation[:, -1])\n",
    "\n",
    "        best_validation_loss = validation_loss\n",
    "\n",
    "        if not silent:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}. \\nLoss on training: {np.mean(batches_loss)} \\nLoss on validation: {validation_loss} \\n##########\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper functions to run each model multiple times and gathering statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [],
   "source": [
    "def run_my_neural_network(network_parameters, train_dataset, test_inputs) -> np.array:\n",
    "    \"\"\"\n",
    "    Train our neural network and predict data from test_inputs\n",
    "    \"\"\"\n",
    "    network = MyNeuralNetwork_New.MyNeuralNetwork(*network_parameters)\n",
    "    network.fit(train_dataset[:, :-1], train_dataset[:, [-1]], batch_size=10)\n",
    "    prediction = network.predict(test_inputs)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "def run_linear_regression(train_dataset, test_inputs) -> np.array:\n",
    "    \"\"\"\n",
    "    Train a linear regression on train_inputs, and predict data for test_inputs\n",
    "    \"\"\"\n",
    "    reg = LinearRegression().fit(train_dataset[:, :-1], train_dataset[:, -1])\n",
    "    prediction = reg.predict(test_inputs)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def run_pytorch_network(network_parameters, train_dataset, test_inputs) -> np.array:\n",
    "    \"\"\"\n",
    "    Train a pytorch network and predict outputs for test_inputs\n",
    "    \"\"\"\n",
    "    network = myPytorchNetwork(*network_parameters)\n",
    "    train_torch_network(network, train_dataset, 30, 10, learning_rate=0.01, silent=True)\n",
    "    prediction = network(torch.from_numpy(test_inputs)).detach().numpy().flatten()\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def measure_model_error_multiple_times(model: Callable, dataset: np.array, train_ratio=0.85, num_runs=5, silent=False):\n",
    "    \"\"\"\n",
    "    :param model: a callable that accepts train dataset, test inputs, and produces the prediction for test inputs\n",
    "    :param dataset: dataset to train on of shape (n_samples, n_features), where the last column is the value to be predicted\n",
    "    :param train_ratio: how much data to put into the training dataset\n",
    "    :param num_runs: number of runs with reshuffled dataset\n",
    "    :param silent: if true, not print any output\n",
    "    :return: mean MSE through all the runs\n",
    "    \"\"\"\n",
    "    split_index = int(dataset.shape[0] * train_ratio)\n",
    "    best_mape = 0\n",
    "    best_mse = float(\"inf\")\n",
    "    for _ in range(num_runs):\n",
    "        np.random.shuffle(dataset)\n",
    "        train = dataset[:split_index, :]\n",
    "        test = dataset[split_index:, :]\n",
    "\n",
    "        prediction = model(train, test[:, :-1]).flatten()\n",
    "        expected = test[:, -1].flatten()\n",
    "        mse = np.mean((prediction - expected) ** 2)\n",
    "        mape = 100 * np.mean(np.abs((prediction - expected) / expected))\n",
    "        if not silent:\n",
    "            print(f\"Model MSE on test: {mse}\")\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_mape = mape\n",
    "\n",
    "    return best_mape, best_mse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "# Load the data\n",
    "turbine = np.genfromtxt(\"processed_datasets/turbine.csv\", dtype=np.float32, delimiter=',', skip_header=1)\n",
    "synthetic = np.genfromtxt(\"processed_datasets/synthetic.csv\", dtype=np.float32, delimiter=',', skip_header=1)\n",
    "boston = np.genfromtxt(\"processed_datasets/boston.csv\", dtype=np.float32, delimiter=',', skip_header=1)\n",
    "turbine_input, turbine_output = turbine[:, :4], turbine[:, 4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Just trying multiple times with different parameters to make sure that everything works"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0013430756516754627\n",
      "Model MSE on test: 0.0009350292384624481\n",
      "Model MSE on test: 0.0014231828972697258\n",
      "Model MSE on test: 0.0010630425531417131\n",
      "Model MSE on test: 0.0010568056022748351\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.001164227188564837"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying a couple of times with different splits into training and test data for a better understanging\n",
    "measure_model_error_multiple_times(run_linear_regression, turbine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0008462416590191424\n",
      "Model MSE on test: 0.0014376954641193151\n",
      "Model MSE on test: 0.0013477603206411004\n",
      "Model MSE on test: 0.0009092555264942348\n",
      "Model MSE on test: 0.0007819987367838621\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.001064590341411531"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now trying, maybe applying some functions to features can make the situation better. There is no obvious relation here, but after trying, we found this gives better results (not always, but mostly better)\n",
    "\n",
    "modified_turbine = turbine.copy()\n",
    "modified_turbine[:, 1] = modified_turbine[:, 1] ** 2\n",
    "modified_turbine[:, 0] = modified_turbine[:, 0] ** 2\n",
    "measure_model_error_multiple_times(run_linear_regression, modified_turbine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0012404868612065911\n",
      "Model MSE on test: 0.0012759158853441477\n"
     ]
    },
    {
     "data": {
      "text/plain": "8.158766105771065"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_model_error_multiple_times(lambda *args: run_pytorch_network([[9, 5, 1], 'tanh'], *args), synthetic, num_runs=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0014333083615438412\n",
      "Model MSE on test: 0.0010935233376317352\n",
      "Model MSE on test: 0.0010191006833360889\n",
      "Model MSE on test: 0.001083210922432468\n",
      "Model MSE on test: 0.0018946499250184826\n"
     ]
    },
    {
     "data": {
      "text/plain": "7.382092207193549"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_model_error_multiple_times(lambda *args: run_my_neural_network([[9, 5, 1], 50, 0.01, 0.9, \"tanh\", 0.2], *args), synthetic, num_runs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston & 4 & [13, 8, 6, 1] & 50 & 0.001 & 0.9 & relu & 17.2 & 0.007 \\\\\n",
      "\\hline\n",
      "boston & 4 & [13, 8, 6, 1] & 50 & 0.01 & 0.9 & relu & 17.1 & 0.004 \\\\\n",
      "\\hline\n",
      "boston & 4 & [13, 8, 6, 1] & 70 & 0.001 & 0.9 & tanh & 14.1 & 0.006 \\\\\n",
      "\\hline\n",
      "boston & 4 & [13, 8, 6, 1] & 50 & 0.01 & 0.9 & tanh & 12.2 & 0.003 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "test_parameters = [\n",
    "    # [\"turbine\", 3, [4, 5, 1], 30, 0.01, 0.9, \"relu\"],\n",
    "    # [\"turbine\", 3, [4, 5, 1], 30, 0.01, 0.9, \"sigmoid\"],\n",
    "    # [\"turbine\", 3, [4, 5, 1], 30, 0.01, 0.9, \"tanh\"],\n",
    "    # [\"turbine\", 3, [4, 5, 1], 30, 0.01, 0.9, \"linear\"],\n",
    "    # [\"synthetic\", 4, [9, 8, 6, 1], 30, 0.01, 0.9, \"relu\"],\n",
    "    # [\"synthetic\", 4, [9, 8, 6, 1], 30, 0.01, 0.9, \"sigmoid\"],\n",
    "    # [\"synthetic\", 4, [9, 8, 6, 1], 30, 0.01, 0.9, \"tanh\"],\n",
    "    # [\"synthetic\", 4, [9, 8, 6, 1], 30, 0.01, 0.9, \"linear\"],\n",
    "    [\"boston\", 4, [13, 8, 6, 1], 50, 0.001, 0.9, \"relu\"],\n",
    "    [\"boston\", 4, [13, 8, 6, 1], 50, 0.01, 0.9, \"relu\"],\n",
    "    [\"boston\", 4, [13, 8, 6, 1], 70, 0.001, 0.9, \"tanh\"],\n",
    "    [\"boston\", 4, [13, 8, 6, 1], 50, 0.01, 0.9, \"tanh\"],\n",
    "]\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# The generated output here can be just copied directly to LaTeX table\n",
    "for parameters in test_parameters:\n",
    "    dataset, n_layers, layers, epochs, lr, momentum, activation = parameters\n",
    "    mape, mse = measure_model_error_multiple_times(lambda *args: run_my_neural_network([layers, epochs, lr, momentum, activation, 0.01], *args), eval(dataset), num_runs=5, silent=True)\n",
    "    print(\" & \".join(map(str, parameters)) + \" & {:.1f} & {:.3f} \\\\\\\\\\n\\\\hline\".format(mape, mse))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3.2\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
