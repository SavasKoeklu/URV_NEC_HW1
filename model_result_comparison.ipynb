{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# pyTorch neural network class\n",
    "\n",
    "class myPytorchNetwork(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(myPytorchNetwork, self).__init__()\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # TODO: I'm using relus everywhere for now, we need to change it to be adjustable\n",
    "        for layer in self.fc_layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "\n",
    "        # No need for activation in the last layer\n",
    "        return self.fc_layers[-1](x)\n",
    "\n",
    "\n",
    "def train_torch_network(network: myPytorchNetwork, dataset, max_epochs, batch_size, train_ratio=0.7,\n",
    "                        learning_rate=0.001, momentum=0.9, silent=False):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # TODO: think of making the learning rate adaptive here, e.g. by using pytorch LR scheduler\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    split_index = int(dataset.shape[0] * train_ratio)\n",
    "    train, validation = dataset[:split_index, :], torch.from_numpy(dataset[split_index:, :])\n",
    "\n",
    "    best_validation_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        np.random.shuffle(train)\n",
    "        torch_train = torch.from_numpy(train)\n",
    "        batch_start_idx = 0\n",
    "\n",
    "        batches_loss = []\n",
    "        # This way we skip last samples if there are less than batch_size of them\n",
    "        while batch_start_idx + batch_size <= torch_train.shape[0]:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = network(torch_train[batch_start_idx:batch_start_idx + batch_size, :-1])\n",
    "            loss = loss_fn(torch.flatten(outputs), torch_train[batch_start_idx:batch_start_idx + batch_size, -1])\n",
    "            batches_loss.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            batch_start_idx += batch_size\n",
    "\n",
    "        # Now, check the loss on validation dataset\n",
    "        validation_output = torch.flatten(network(validation[:, :-1]))\n",
    "        validation_loss = loss_fn(validation_output, validation[:, -1])\n",
    "\n",
    "        # # If the validation loss starts to increase, stop training\n",
    "        # if validation_loss > best_validation_loss:\n",
    "        #     print(f\"Epoch: {epoch}. \\nValidation loss increased from {best_validation_loss} to {validation_loss}. Stopping training\")\n",
    "        #     return\n",
    "\n",
    "        best_validation_loss = validation_loss\n",
    "\n",
    "        if not silent:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}. \\nLoss on training: {np.mean(batches_loss)} \\nLoss on validation: {validation_loss} \\n##########\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def run_linear_regression(train_dataset, test_inputs) -> np.array:\n",
    "    \"\"\"\n",
    "    Train a linear regression on train_inputs, and predict data for test_inputs\n",
    "    \"\"\"\n",
    "    reg = LinearRegression().fit(train_dataset[:, :-1], train_dataset[:, -1])\n",
    "    prediction = reg.predict(test_inputs)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def run_pytorch_network(network, train_dataset, test_inputs) -> np.array:\n",
    "    \"\"\"\n",
    "    Train a pytorch network and predict outputs for test_inputs\n",
    "    \"\"\"\n",
    "    # TODO: make this adjustable from the outside\n",
    "    train_torch_network(network, train_dataset, 50, 10, learning_rate=0.01, silent=True)\n",
    "    prediction = network(torch.from_numpy(test_inputs)).detach().numpy().flatten()\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def measure_model_error_multiple_times(model: Callable, dataset: np.array, train_ratio=0.85, num_runs=5):\n",
    "    \"\"\"\n",
    "    :param model: a callable that accepts train dataset, test inputs, and produces the prediction for test inputs\n",
    "    :param dataset: dataset to train on of shape (n_samples, n_features), where the last column is the value to be predicted\n",
    "    :param train_ratio: how much data to put into the training dataset\n",
    "    :param num_runs: number of runs with reshuffled dataset\n",
    "    :return: mean MSE through all the runs\n",
    "    \"\"\"\n",
    "    split_index = int(dataset.shape[0] * train_ratio)\n",
    "    error_sum = 0\n",
    "    for _ in range(num_runs):\n",
    "        np.random.shuffle(dataset)\n",
    "        train = dataset[:split_index, :]\n",
    "        test = dataset[split_index:, :]\n",
    "\n",
    "        prediction = model(train, test[:, :-1])\n",
    "        mse = np.mean((prediction - test[:, -1].flatten()) ** 2)\n",
    "        print(f\"Model MSE on test: {mse}\")\n",
    "        error_sum += mse\n",
    "    return error_sum / num_runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# Load the data. TODO: add all the datasets here\n",
    "turbine = np.genfromtxt(\"processed_datasets/turbine.csv\", dtype=np.float32, delimiter=',', skip_header=1)\n",
    "turbine_input, turbine_output = turbine[:, :4], turbine[:, 4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0011528179747983813\n",
      "Model MSE on test: 0.002424795413389802\n",
      "Model MSE on test: 0.001376274973154068\n",
      "Model MSE on test: 0.001286662882193923\n",
      "Model MSE on test: 0.0014885530108585954\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.001545820850878954"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying a couple of times with different splits into training and test data for a better understanging\n",
    "measure_model_error_multiple_times(run_linear_regression, turbine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0014316097367554903\n",
      "Model MSE on test: 0.001650119898840785\n",
      "Model MSE on test: 0.0013921308564022183\n",
      "Model MSE on test: 0.0017579963896423578\n",
      "Model MSE on test: 0.0012379592517390847\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0014939632266759873"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now trying, maybe applying some functions to features can make the situation better. There is no obvious relation here, but after trying, we found this gives better results (not always, but mostly better)\n",
    "\n",
    "modified_turbine = turbine.copy()\n",
    "modified_turbine[:, 1] = modified_turbine[:, 1] ** 2\n",
    "modified_turbine[:, 0] = modified_turbine[:, 0] ** 2\n",
    "measure_model_error_multiple_times(run_linear_regression, modified_turbine)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "(451, 5)"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE on test: 0.0003147642419207841\n",
      "Model MSE on test: 0.00028935971204191446\n",
      "Model MSE on test: 0.00017892543110065162\n",
      "Model MSE on test: 0.00016714140656404197\n",
      "Model MSE on test: 0.00020081765251234174\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.00023020168882794678"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_nn = myPytorchNetwork([4, 8, 10, 1])\n",
    "measure_model_error_multiple_times(lambda *args: run_pytorch_network(torch_nn, *args), turbine, num_runs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
